# Recommendation System Strategies - Best Practices Analysis

**Date**: November 27, 2025  
**Context**: Ph√¢n t√≠ch chi·∫øn l∆∞·ª£c recommendation c·ªßa c√°c h·ªá th·ªëng l·ªõn ƒë·ªÉ √°p d·ª•ng v√†o Job Recommendation System

---

## I. PH√ÇN T√çCH C√ÅC H·ªÜ TH·ªêNG L·ªöN

### 1. **LinkedIn Jobs** (T∆∞∆°ng t·ª± nh·∫•t v·ªõi project)

#### Strategy Stack (Multi-layered Fallback)

```
Layer 1: Personalized Semantic Search
‚îú‚îÄ Vector similarity (user skills √ó job embeddings)
‚îú‚îÄ Collaborative filtering (users with similar profiles)
‚îî‚îÄ If insufficient results ‚Üí Layer 2

Layer 2: Demographic Matching
‚îú‚îÄ Location-based filtering
‚îú‚îÄ Experience level matching
‚îú‚îÄ Industry similarity
‚îî‚îÄ If insufficient results ‚Üí Layer 3

Layer 3: Popular Jobs (Trending)
‚îú‚îÄ Most viewed jobs in location
‚îú‚îÄ Most applied jobs in industry
‚îú‚îÄ Recently posted jobs
‚îî‚îÄ If insufficient results ‚Üí Layer 4

Layer 4: Expanded Search
‚îú‚îÄ Relax location constraint (nearby cities)
‚îú‚îÄ Relax experience level (¬±1 level)
‚îú‚îÄ Show "remote jobs" regardless of location
‚îî‚îÄ Always return results
```

**Missing Data Handling**:

- **No salary data**: Show anyway, mark "Salary not provided"
- **No location**: Default to "Remote" or "United States"
- **No skills**: Use job title for semantic search
- **No experience level**: Mark "Not specified", don't filter

---

### 2. **Indeed.com**

#### Strategy Stack

```
Layer 1: Exact Match + Semantic
‚îú‚îÄ Query parsing (job title, skills, location)
‚îú‚îÄ TF-IDF keyword matching
‚îú‚îÄ Semantic embedding similarity
‚îî‚îÄ Minimum 20 results required

Layer 2: Partial Match
‚îú‚îÄ Remove least important filter (salary first)
‚îú‚îÄ Relax location (expand radius)
‚îú‚îÄ Relax keywords (synonyms)
‚îî‚îÄ Minimum 10 results required

Layer 3: Related Jobs
‚îú‚îÄ "Jobs similar to this search"
‚îú‚îÄ Same industry, different titles
‚îú‚îÄ Same location, different skills
‚îî‚îÄ Always show results

Layer 4: Sponsored Jobs (Business Model)
‚îú‚îÄ Companies pay for visibility
‚îú‚îÄ Mixed with organic results
‚îî‚îÄ Guaranteed never empty
```

**Missing Data Handling**:

- **No salary**: Don't filter, show "Competitive salary"
- **No remote flag**: Assume "On-site" (safer default)
- **No company info**: Show "Hiring Company"
- **Incomplete description**: Use title + industry for search

---

### 3. **Netflix** (Reference for Recommendation Logic)

#### Hybrid Strategy

```
1. Content-Based Filtering (50%)
   ‚îú‚îÄ Genre similarity
   ‚îú‚îÄ Director/Actor overlap
   ‚îú‚îÄ Year/Duration match
   ‚îî‚îÄ TF-IDF on descriptions

2. Collaborative Filtering (30%)
   ‚îú‚îÄ Users who watched X also watched Y
   ‚îú‚îÄ Implicit feedback (watch time, completion rate)
   ‚îî‚îÄ Matrix factorization

3. Trending/Popular (20%)
   ‚îú‚îÄ Time-decay popularity
   ‚îú‚îÄ Regional trending
   ‚îî‚îÄ New releases boost
```

**Missing Data Handling**:

- **No user history**: Start with popular items
- **New user (cold start)**: Ask preferences ‚Üí instant personalization
- **New item (cold start)**: Boost visibility for first 48h
- **No genre tags**: Use description embeddings

---

### 4. **Amazon** (E-commerce Recommendation)

#### Multi-Algorithm Approach

```
1. Item-to-Item Collaborative Filtering (Primary)
   ‚îî‚îÄ "Customers who bought X also bought Y"

2. Content-Based (Fallback)
   ‚îî‚îÄ Product attributes, category, brand

3. Context-Aware
   ‚îú‚îÄ Time of day (breakfast ‚Üí coffee)
   ‚îú‚îÄ Season (winter ‚Üí heaters)
   ‚îî‚îÄ Current cart items

4. Social Proof
   ‚îú‚îÄ "Bestseller in category"
   ‚îú‚îÄ "Highly rated"
   ‚îî‚îÄ "Trending now"
```

---

## II. CHI·∫æN L∆Ø·ª¢C CHO JOB RECOMMENDATION SYSTEM

### Recommended Strategy Stack (LinkedIn-inspired)

```python
def get_recommendations_with_fallback(query, filters, top_k=20):
    """
    Multi-layer recommendation v·ªõi automatic fallback
    """

    # LAYER 1: SEMANTIC SEARCH v·ªõi t·∫•t c·∫£ filters
    results = semantic_search(query, filters, fetch_k=top_k * 15)
    if len(results) >= top_k:
        return results.head(top_k)

    # LAYER 2: RELAX SALARY FILTER (least reliable data)
    if 'min_salary' in filters or 'max_salary' in filters:
        relaxed_filters = {k: v for k, v in filters.items()
                          if k not in ['min_salary', 'max_salary']}
        results = semantic_search(query, relaxed_filters, fetch_k=top_k * 12)
        if len(results) >= top_k:
            return results.head(top_k)

    # LAYER 3: RELAX EXPERIENCE LEVEL
    if 'experience_level' in filters:
        relaxed_filters = {k: v for k, v in filters.items()
                          if k != 'experience_level'}
        results = semantic_search(query, relaxed_filters, fetch_k=top_k * 10)
        if len(results) >= top_k:
            return results.head(top_k)

    # LAYER 4: LOCATION EXPANSION (nearby cities)
    if 'location' in filters:
        expanded_filters = filters.copy()
        expanded_filters['location'] = expand_location(filters['location'])
        results = semantic_search(query, expanded_filters, fetch_k=top_k * 8)
        if len(results) >= top_k:
            return results.head(top_k)

    # LAYER 5: QUERY-ONLY (no filters)
    results = semantic_search(query, filters={}, fetch_k=top_k * 5)
    if len(results) >= top_k:
        return results.head(top_k)

    # LAYER 6: POPULAR JOBS (last resort)
    return get_popular_jobs_in_category(query, top_k)
```

### Missing Data Handling Strategies

```python
class DataQualityHandler:
    """Handle missing/incomplete data gracefully"""

    @staticmethod
    def handle_missing_salary(job_row):
        """Salary missing: don't exclude, mark as 'Not specified'"""
        if pd.isna(job_row['salary_median']):
            job_row['salary_display'] = "Competitive salary"
            job_row['has_salary_info'] = False
        else:
            job_row['salary_display'] = format_salary(job_row)
            job_row['has_salary_info'] = True
        return job_row

    @staticmethod
    def handle_missing_location(job_row):
        """Location missing: infer or default"""
        if pd.isna(job_row['location']):
            # Strategy 1: Infer from company
            if pd.notna(job_row['company_city']):
                job_row['location'] = job_row['company_city']
            # Strategy 2: Check remote flag
            elif job_row.get('remote_allowed') == 1:
                job_row['location'] = "Remote"
            # Strategy 3: Default
            else:
                job_row['location'] = "United States"
        return job_row

    @staticmethod
    def handle_missing_work_type(job_row):
        """Work type missing: infer from other fields"""
        if pd.isna(job_row['formatted_work_type']):
            # Strategy 1: Check original work_type
            if pd.notna(job_row.get('work_type')):
                job_row['formatted_work_type'] = standardize_work_type(
                    job_row['work_type']
                )
            # Strategy 2: Infer from compensation
            elif 'hourly' in str(job_row.get('pay_period', '')).lower():
                job_row['formatted_work_type'] = "Part-time"
            # Strategy 3: Default to most common
            else:
                job_row['formatted_work_type'] = "Full-time"
        return job_row

    @staticmethod
    def handle_missing_skills(job_row):
        """Skills missing: extract from description"""
        if pd.isna(job_row['skills']) or job_row['skills'] == "":
            # Extract skills from description using NLP
            extracted = extract_skills_from_text(
                job_row['title'] + " " + job_row['description']
            )
            job_row['skills'] = ", ".join(extracted) if extracted else "Not specified"
            job_row['skills_source'] = "extracted"
        else:
            job_row['skills_source'] = "original"
        return job_row

    @staticmethod
    def handle_missing_experience(job_row):
        """Experience level missing: infer from title"""
        if pd.isna(job_row['formatted_experience_level']):
            title_lower = str(job_row['title']).lower()

            # Pattern matching
            if any(word in title_lower for word in ['senior', 'sr.', 'lead', 'principal']):
                job_row['formatted_experience_level'] = "Mid-Senior level"
            elif any(word in title_lower for word in ['junior', 'jr.', 'entry', 'associate']):
                job_row['formatted_experience_level'] = "Entry level"
            elif any(word in title_lower for word in ['director', 'vp', 'head of', 'chief']):
                job_row['formatted_experience_level'] = "Director"
            elif 'intern' in title_lower:
                job_row['formatted_experience_level'] = "Internship"
            else:
                job_row['formatted_experience_level'] = "Mid-Senior level"  # Most common
        return job_row
```

---

## III. IMPLEMENTATION PRIORITIES

### Phase 1: Critical Missing Data Handling (NOW)

1. **Auto-fill missing work_type** ‚úÖ

   ```python
   df['formatted_work_type'] = df['formatted_work_type'].fillna('Full-time')
   ```

2. **Auto-fill missing location** ‚úÖ

   ```python
   df['location'] = df.apply(lambda x:
       x['company_city'] if pd.isna(x['location']) and pd.notna(x['company_city'])
       else 'Remote' if x.get('remote_allowed') == 1
       else 'United States'
       , axis=1)
   ```

3. **Auto-fill missing experience** ‚úÖ
   ```python
   df['formatted_experience_level'] = df.apply(
       infer_experience_from_title, axis=1
   )
   ```

### Phase 2: Fallback Strategy (NEXT)

1. **Implement progressive filter relaxation**

   - Start with all filters
   - Remove salary ‚Üí experience ‚Üí location
   - Always return results

2. **Add "Related Jobs" section**

   - Show jobs even when primary search fails
   - "Jobs similar to your search"

3. **Popular jobs fallback**
   - Cache trending jobs daily
   - Use when filters too restrictive

### Phase 3: Advanced Features (FUTURE)

1. **Smart defaults based on query**

   ```python
   if "remote" in query.lower():
       filters['remote_allowed'] = True
   if "senior" in query.lower():
       filters['experience_level'] = "Mid-Senior level"
   ```

2. **Location expansion**

   ```python
   NEARBY_CITIES = {
       'San Francisco': ['San Jose', 'Oakland', 'Palo Alto', 'Bay Area'],
       'New York': ['Brooklyn', 'Queens', 'Manhattan', 'NYC'],
   }
   ```

3. **Skill synonym matching**
   ```python
   SKILL_SYNONYMS = {
       'python': ['py', 'python3', 'django', 'flask'],
       'javascript': ['js', 'react', 'angular', 'vue'],
   }
   ```

---

## IV. ƒê√ÅNH GI√Å V·ªöI Y√äU C·∫¶U PROJECT

### Y√™u c·∫ßu t·ª´ FinalProject_recommendation_system.md

| Y√™u c·∫ßu                             | Hi·ªán t·∫°i                   | C·∫ßn th√™m                |
| ----------------------------------- | -------------------------- | ----------------------- |
| **2. L√†m s·∫°ch d·ªØ li·ªáu (3/7 tasks)** | ‚úÖ                         |                         |
| - Missing values                    | ‚úÖ Fill Unknown            | ‚ö†Ô∏è C·∫ßn smart imputation |
| - Chu·∫©n h√≥a                         | ‚úÖ Text cleaning           | ‚úÖ                      |
| - Lo·∫°i b·ªè duplicates                | ‚úÖ                         | ‚úÖ                      |
| - Vector h√≥a                        | ‚úÖ TF-IDF + MiniLM         | ‚úÖ                      |
| **3. EDA (3/4 tasks)**              | ‚úÖ                         |                         |
| - Ph√¢n b·ªë                           | ‚úÖ Work type, location     | ‚úÖ                      |
| - Top items                         | ‚úÖ Skills, industries      | ‚úÖ                      |
| - Heatmap/charts                    | ‚úÖ                         | ‚úÖ                      |
| **4. X√¢y d·ª±ng h·ªá g·ª£i √Ω**            | ‚úÖ                         | ‚ö†Ô∏è                      |
| - Model                             | ‚úÖ TF-IDF + MiniLM + FAISS | ‚úÖ                      |
| - **Fallback strategy**             | ‚ùå **THI·∫æU**               | üî¥ **CRITICAL**         |
| **5. ƒê√°nh gi√°**                     | ‚úÖ                         |                         |
| - Precision@K                       | ‚úÖ P@5: 94.3%, P@10: 90%   | ‚úÖ                      |
| **6. Giao di·ªán**                    | ‚úÖ                         |                         |
| - Streamlit                         | ‚úÖ Indeed-style UI         | ‚úÖ                      |
| **N√¢ng cao**                        |                            |                         |
| - Embeddings                        | ‚úÖ MiniLM                  | ‚úÖ                      |
| - Real-time                         | ‚úÖ FAISS <20ms             | ‚úÖ                      |
| - L·ªãch s·ª≠                           | ‚úÖ query_history.json      | ‚úÖ                      |
| - Context-aware                     | ‚ùå                         | üü° Optional             |

---

## V. KHUY·∫æN NGH·ªä TRI·ªÇN KHAI

### Immediate (Day 7+)

1. ‚úÖ **Add progressive filter relaxation** (30 mins)
2. ‚úÖ **Implement smart missing data imputation** (1 hour)
3. ‚úÖ **Add "no results" fallback to popular jobs** (30 mins)

### Short-term (Day 8)

1. **Location expansion logic** (1 hour)
2. **Experience level inference from title** (30 mins)
3. **Skill extraction from description** (1 hour)

### Long-term (Post-submission)

1. **Collaborative filtering** (users with similar profiles)
2. **Time-decay popularity ranking**
3. **A/B testing framework**

---

## VI. CODE EXAMPLES

### Example 1: Progressive Filter Relaxation

```python
def get_recommendations_smart(query, filters, top_k=20):
    """Progressively relax filters until sufficient results"""

    filter_priority = [
        'min_salary',      # Relax first (least reliable)
        'max_salary',
        'experience_level',
        'remote_allowed',
        'location',        # Relax last (most important)
    ]

    # Try with all filters
    results = search_with_filters(query, filters, top_k * 12)
    if len(results) >= top_k:
        return results.head(top_k), "exact_match"

    # Progressively remove filters
    working_filters = filters.copy()
    for filter_key in filter_priority:
        if filter_key in working_filters:
            removed_value = working_filters.pop(filter_key)
            results = search_with_filters(query, working_filters, top_k * 10)

            if len(results) >= top_k:
                return results.head(top_k), f"relaxed_{filter_key}"

    # Last resort: no filters
    results = search_with_filters(query, {}, top_k * 5)
    return results.head(top_k), "query_only"
```

### Example 2: Smart Missing Data Handler

```python
def preprocess_with_smart_imputation(df):
    """Apply smart imputation strategies"""

    # 1. Work type
    df['formatted_work_type'] = df.apply(
        lambda x: infer_work_type(x) if pd.isna(x['formatted_work_type'])
        else x['formatted_work_type'],
        axis=1
    )

    # 2. Location
    df['location'] = df.apply(infer_location, axis=1)

    # 3. Experience
    df['formatted_experience_level'] = df.apply(
        infer_experience, axis=1
    )

    # 4. Salary (mark as missing, don't impute)
    df['has_salary'] = df['salary_median'].notna()

    return df
```

---

## Conclusion

**Current Gap**: H·ªá th·ªëng thi·∫øu fallback strategies ‚Üí User tr·∫£i nghi·ªám k√©m khi filters qu√° strict.

**Best Practice**: LinkedIn/Indeed approach v·ªõi multi-layer fallback.

**Action Items**:

1. Implement progressive filter relaxation
2. Add smart missing data imputation
3. Always return results (never empty state)
